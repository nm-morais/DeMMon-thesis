%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% chapter1.tex
%% NOVA thesis document file
%%
%% Chapter with introduction
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\novathesis}{\emph{novathesis}}
\newcommand{\novathesisclass}{\texttt{novathesis.cls}}

\chapter{Introduction}
\label{cha:introduction}

\section{Motivation}

Nowadays, the Cloud Computing paradigm is the standard for development, deployment and management of services, and most of the software present in our everyday life such as Google Apps, Amazon, Twitter, among many others is deployed on some form of cloud service. Cloud Computing refers to both the applications delivered as services over the Internet and the hardware and systems software in the data centers that provide those services \cite{10.1145/1721654.1721672}, it provides the illusion of unlimited computing power which revolutionized the way developers, companies and users rationalize applications.

However, the centralized model proposed by the Cloud Computing paradigm differs from the rise in popularity of many types of applications \cite{10.1145/3154815} such as: latency-sensitive applications; geo-distributed applications, fast mobile applications, and IoT applications. When the computation resides in the data center (DC), far from the source of the data, problems arise: from the physical space needed to contain all the infrastructure, the increasing amount of bandwidth needed to support the information exchange from the DC to the client, the latency in communication from the client to the DC as well as the security aspects that arise from offloading data storage and computation have directed us into a new computing paradigm, \textit{Edge Computing}.

Edge computing addresses the increasing need for enriching the interaction between cloud computing systems and mobile or IoT applications by taking into consideration all the computing and networking resources which act as an "edge"\ along the path between the data source and the DC \cite{Leitao2018} \cite{7488250}. It enables the creation of systems which could otherwise be unfeasible with Cloud Computing: Google's self-driving car generates 1 Gigabyte every second \cite{datafloq}, and a Boeing 787 will create around 5 gigabytes of data per second \cite{finnegan_2013}, which would be unfeasible to transport and process in real-time (e.g. towards self-driving) if the computations were to be carried in a DC. 

By accounting all the devices that are external to the DC, we are met by a huge increase in available devices: from Data Centers to private servers, desktops and mobile devices to 5G towers and ISP servers. These devices, contrary to the cloud, often have heterogenous computational capacity and unreliable connections. Given this, developing an efficient resource sharing platform which employs these devices efficiently is still an open challenge in Edge Computing. 

\section{Context}

Resource sharing platforms are extensibly used in Cloud systems (e.g. Mesosphere \cite{hindman2011mesos}, Yarn \cite{Vavilapalli2013ApacheHY}, Omega \cite{41684}, among others), whose high-level functionality consist of: (1) federating all the devices and tracking their state and utilization of computational and networking resources; (2) keeping track of resource demands which arise from tenants; (3) performing resource allocations which satisfy the needs of tenants; (4) adapting to workloads such that the system remains balanced and system policies are being met.

Most popular resource sharing platforms are tailored towards small numbers of homogenous resource-heavy devices, which rely on transporting all of the system information towards a centralized system component that performs resource allocations with global knowledge of the system. Although this system architecture heavily simplifies the system behavior, we argue such system with a centralized point of failure and single point of contention is unfeasible for a large scale system, and that participants with only partial knowledge of the system must be able to cooperatively control the available resources. 

Given this, it is paramount that devices cooperatively materialize a robust lightweight decentralized resource control system, which tracks resource demands and allocations. In such a system, the accuracy and freshness of the information each peer has dictates how efficiently they manage resources such that the system remains balanced, and applications running on the infrastructure maintain quality of service. This system must federate peers such that they leverage on heterogeneity to build a hierarchical infrastructure which combines naturally with the device taxonomy, and adapts to the environment changes. 

\section{Expected Contributions}

The expected contributions, as will be further detailed in chapter \ref{cha:planning}, arise from the aforementioned challenges, we will focus on creating a decentralized resource monitoring and management solution tailored for provisioning resources for edge-enabled applications. Given this, the contributions expected to arise from our work consist of: 

\begin{itemize}

    \item A novel algorithm which constructs an overlay tailored towards federating large numbers of edge devices in a hierarchical way.
    
    \item A lightweight monitoring solution which relies on the overlay structure to aggregate information regarding applicationsâ€™ operation and the load of edge resources.
    
    \item A decentralized resource management solution capable of satisfying resource allocations for multi-tenant resource sharing.

    \item Design an experimental scenario for the system and collect metrics to evaluate the performance and correctness of designed components. Additionally, we may design or adapt an existing edge-enabled application to test the solution in a real world scenario by scheduling application deployments and tracking metrics about the overlay and the quality of service of the applications.
    
\end{itemize}

\section{Document structure}

This document is structured in the following manner:

\textbf{Chapter} \ref{cha:related_work} studies related work towards our goal: we begin by analyzing similar paradigms to Edge Computing, and the devices which compose these environments. Following, we cover popular strategies towards federating various devices in the same system, how to efficiently find a specific peer in such systems and common techniques towards performing efficient resource discovery over large numbers of devices. Lastly, we study execution environments, monitoring of system resources and resource sharing systems.

\textbf{Chapter} \ref{cha:planning} further explains the proposed contribution and the proposed work plan for the remainder of the thesis. 
