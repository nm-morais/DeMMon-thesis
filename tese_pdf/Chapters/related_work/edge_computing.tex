
In this section we provide context about edge-related paradigms, study the taxonomy of the devices which materialize edge environments and analyze which computations each device can perform.

\subsection{Edge Computing}

As previously mentioned, edge computing calls for the processing of data (and potentially storage) across all the devices which act as an "edge"\ along the path from the data center (DC) do the data source or client device \cite{Leitao2018}. It has the potential of enabling novel edge-enabled applications along with optimizing existing systems \cite{7488250}, making them more responsive.

%\begin{itemize}
%
%    \item \textbf{Reducing the amount of traffic}, Edge Computing has the potential to reduce the amount of data exchanged between the Edge and the Cloud. For example, in the case of a smart home which computes the average home temperature in all divisions, almost all the data collected by the sensors can be aggregated (averaged) in a home gateway, effectively summarizing the data from a set of values to a single value, which is then sent to the Cloud pre-processed. Reducing the size of the data effectively improves transmission reliability and reduces infrastructure cost for both users and application / cloud operators. 
%    
%    \item \textbf{Reducing Latency} is one of the most important benefits, especially towards time-critical applications (e.g. traffic monitoring) which have special latency needs. Latency consists in the time it takes for a packet to travel the network from the origin endpoint to the target endpoint. Edge computing proposes to improve this by, for example, transferring the computation to the edge node closest to the data requests.
%
%    \item Facilitating new approaches of \textbf{load-balancing}, given that there is a massive increase of devices in the edge of the network, applications may load-balance themselves by offloading tasks towards the nearest available device with enough capacity, or by migrating an entire application towards a nearby device with higher capacity.
%    
%    \item \textbf{Minimizing energy consumption}, edge computing has the potential of optimizing the resource distributions towards saving energy. For example, a device which has low battery but belongs to time-critical service can chose to offload any unnecessary computations towards neighbors as a cost-saving measure. 
%    
%\end{itemize}

Many approaches have already leveraged on some form of Edge computing in the past. \textbf{Cloudlets} \cite{10.1145/2307849.2307858} are an extension of the cloud computing paradigm beyond the DC, and consists in deploying resource rich computers near the vicinity of users that provide cloud functionality. They have become a trending subject, and have been employed towards resource management, Big Data analytics, security, among others. However, a limitation of Cloudlets is that because they are specialized computers, they cannot guarantee low-latency ubiquitous service provision, and cannot ensure that applications behave correctly in the presence of large hotspots of users. 

\textbf{Content Distribution networks} \cite{peng2004cdn} (CDNs) emerged to address the overwhelming utilization of network bandwidth and server capacity that arose with bandwidth-intensive content (e.g. streaming HD video). In short, CDNs consist of specialized high bandwidth servers strategically located at the edge of the network which replicate content from a certain origin and serve it at reduced latencies, effectively decentralizing the content delivery. 

\textbf{Fog Computing} \cite{bonomi2012fog} is paradigm which aims at solving similar problems to the Edge Computing. It proposes to provide computing, storage and networking services between end devices and traditional cloud computing data centers, typically, but not exclusively located at the edge of the network. We consider fog computing to be interchangeable with our definition of Edge Computing, however, with a special emphasis on providing infrastructure for edge-enabled services, instead of focusing on the inter-cooperation among devices.

\textbf{Osmotic Computing} \cite{villari2016osmotic} envisions the automatic deployment and management of inter-connected microservices deployed over a seamless infrastructure composed of both edge and cloud devices. This is accomplished by employing an orchestration technique similar to the process of "osmosis". Translated, this consists in dynamically detecting and resolving resource contention via coordinated microservice deployments in edge devices. In our view, this paradigm is a subset of Edge Computing, because it only focuses on deploying microservices on edge devices instead of employing them towards generic computations, and the original authors only mention deploying services over CLoud and Edge DCs, instead of the whole range of possible devices.

\textbf{Multi-access edge computing} \cite{mobile_edge_cloud} (MEC), formerly known as mobile-edge cloud computing, is a network architecture which proposes to provide fast-interactive responses for mobile applications. It solves this by employing the devices in the edge (e.g. base stations and access points) to provide compute resources for latency-critical mobile applications (e.g. facial recognition). Similar to Osmotic Computing, we consider MEC a subset of edge computing, given that its primary focus is on how to offload the computation from mobile to the cloud and not vice-versa. 

\subsection{Edge Environment Taxonomy} \label{subsec:edge_taxonomy}

According to \textcite{Leitao2018}, edge devices may be classified according to three main attributes: \textbf{capacity} refers to computational, storage and connectivity capabilities of the device,  \textbf{availability} consists in the probability of a device being reachable, and finally, \textbf{domain} characterizes the way in which a device may be employed towards applications, either by performing actions on behalf of users (user domain) or performing actions on behalf of applications (applicational domain). Given that the concern of our work is towards building the underlying infrastructure for these applications, we will only focus on capacity and availability when classifying the taxonomy of the environment. 

\begin{table}[!htb]
    \caption{Taxonomy of the edge environment}
    \begin{minipage}{.45\linewidth}
        \centering
        \resizebox{\columnwidth}{!}{%
        \begin{tabular}{|l|l|l|l|}
            \hline
            Level & Category & Availability & Capacity \\ \hline
            L0 & Cloud Data Centers & High & High \\ \hline
            L1 & ISP, Edge \& Private DCs & High & High \\ \hline
            L2 & 5G Towers & High & Medium \\ \hline
            L3 & Networking devices & High & Low \\ \hline
        \end{tabular}}
    \end{minipage} %
    \begin{minipage}{.45\linewidth}
        \centering
        \resizebox{\columnwidth}{!}{%
            \begin{tabular}{|l|l|l|l|}
                \hline
                Level & Category & Availability & Capacity \\ \hline
                L4 & Priv. Servers \& Desktops & Medium & Medium \\ \hline
                L5 &Laptops & Low & Medium \\ \hline
                L6 &Mobile devices & Low & Low \\ \hline
                L7 &Actuators \& Sensors & Varied & Low \\ \hline   
        \end{tabular}}
    \end{minipage} 
    \label{tab:taxonomy_edge}
\end{table}

Table \ref{tab:taxonomy_edge} shows the categories of edge devices, we assign levels to categories as a function of the distance from the cloud infrastructure. Coincidently, the levels are correlated to the number of devices and their computational power, where higher levels tend to have more devices that are closer to the origin of the data and have lower computational power.

\textbf{Levels 0 and 1}, composed of \textit{cloud and edge DCs}, offer pools of computational and storage resources which can dynamically scale to support the operation of edge-enabled applications. Both of these options have high availability and large amounts of storage and computational power, as such, there is no limitations on the kinds of computations these devices can perform.

\textbf{Levels 2 and 3} are composed of \textit{networking devices}, namely 
\textit{5G cell towers} and \textit{routers, switches}, and \textit{access points}. 5G towers serve as access points for mobile devices, and have higher capacity when compared to routers or switches. Devices in both levels have high availability, and are can easily improve the management of the network, for example, by manipulating data flows among different components of applications (executing in different devices).

\textbf{Level 4} Consists of \textit{private servers} and \textit{desktops}, devices in this level have medium capacity and availability and can perform a varied amount of tasks on behalf of devices in higher levels (e.g. compute on behalf of smartphones, act as logical gateways or just cache data). 

\textbf{Level 5} consists of \textit{laptops}, which can perform a role similar to devices in level 4, although with lower availability and capacity. The main differentiating factor with devices in level 4 is that laptops are battery-powered, which means that energy consumption must also be taken into account whenever monitoring and computing on these devices. 

\textbf{Level 6} consists of \textit{tablets} and \textit{mobile devices}, which have low capacity, availability, and short battery life. Given this, they are limited in how they can perform contribute towards edge applications. Aside from caching user data, they may filter or aggregate of data generated from devices in level 7. 

Finally, \textbf{level 7} consists of \textit{actuators, sensors} and \textit{things}, these devices are the most limited in their capacity, and varied availability. \textit{Things} act both as data producers and consumers towards edge-enabled applications. They enable limited forms of computation in the form of aggregation and filtering.

\subsection{Discussion}

Intuitively, the lower the level the harder it is to employ edge devices to support the execution of edge-enabled applications. Devices in levels 6 and 7 are especially restricted due to having lower availability and computational power, however, these can still be used in specific scenarios (e.g. an application with very low computational overhead but real-time latency requirements). 

Devices in levels 0-5 are potential candidates towards building the resource management and monitoring system we intend to create. The low availability and potential mobility of devices in higher levels make them unsuitable, as they could potentially be a source of instability in the system. This effect can be circumvented by employing devices in other levels as gateways for those devices, hence starting to establish a hierarchy on the way different application components interact.