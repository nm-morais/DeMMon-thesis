
In this section we will cover \textbf{resource monitoring}, we classify resource monitoring as tracking the state of a certain aspect of the system, either device state, the links between devices, or the available computing power in a certain area of the network. Monitoring is key to the effective management of the topology as well the applications running on it.

\subsection{Device monitoring}

In order to adapt edge computing applications to changes in the environment and ensure that the above requirements can be met, it is necessary to tailor the monitoring system to support the whole spectrum of underlying infrastructures (section \ref{sec:edge_computing}). 

A modern approach towards deploying systems is to deploy them in loosely coupled independent components running some form of virtualization software, as it enables co-deployment of logical machines in the same physical node. As such,for we study the two most common types of virtualization (Containers and Virtual Machines (VMs)). 

\subsubsection{Virtual Machines}

In virtual machines (VMs), all the physical resources can be virtualized (CPU, memory, disk and network). Multiple VMs can co-deployed in the same physical node and thus share resources among each other. 

In order to have efficient resource utilization and prevent any problems in the virtualized resources, monitoring of VMs is critical. This can be best achieved by tracking the utilization of the virtualized resources, mainly usage of CPU, memory, storage and network.

\begin{itemize}

    \item \textbf{CPU} usage tracks the amount of usage of the CPU as a percentage of all available CPU to the machine. It is never desirable that the CPU usage reaches 100\%, as queues start filling up and it means that the device has run out of capacity for processing tasks.
    
    \item \textbf{Memory} indicates the amount of virtualized memory left.
    
    \item \textbf{Disk usage} tracks the amount of data read or written by a VM. Alternatively, it can indicate the percentage of used space.

    \item \textbf{Network usage} consists in the volume of traffic on a specific network interface of the VM, either external or internal traffic.

\end{itemize}

Although VMs are widely present in the cloud infrastructure, we believe their applicability towards edge scenarios is limited, due to the fact that they have significant start up time (having to start-up an OS).  

\subsubsection{Containers}

Containers are the recent alternative to VMs, as previously mentioned, containers do not require an OS to boot up \cite{}, and the images that compose them are significantly smaller. Container-based virtualization can be compared to an OS running on bare-metal in terms of memory, CPU and disk usage, however at a cost of network utilization \cite{preeth2015evaluation}, which makes them an attractive options towards resource-constrained devices.

Due to their lightweight nature, it is possible to deploy container-based applications (e.g. microservices), which can perform fast migration across nodes in the edge environment in order to improve QoS. This flexibility towards the migration process is an efficient tool to deal with many challenges such as load balancing, scaling, resource reallocation and fault-tolerance. 

There are many container-specific tools which provide statistics about a given container, most use REST APIs to expose this functionality to external entities. Docker \cite{docker}, which is a container provider, \textcolor{red}{citação?} has a built tool called \textit{docker stats} \cite{docker_stats} which provides runtime metrics for a given container.

\textit{Container Advisor} \cite{cAdvisor} (cAdvisor) is a service which analyzes and exposes resource usage and performance data from running containers. Simply put, cAdvisor consists of a daemon which collects, aggregates and exports information. The information it collects resource isolation parameters, historical resource usage and network statistics. cAdvisor includes native support for Docker containers and supports a wide variety of other container implementations.


\subsection{End-to-end link monitoring}

Given that the edge infrastructure envisions cooperation from all devices in the path from the origin of the data to the DC, devices need to be interconnected across an underlying infrastructure which is continuously changing. This raises concerns about the network quality of links between devices across the system, especially if they are running time-critical services. 

It is paramount to analyze how to monitor and improve link quality, for providing traffic locality, latency, among others. According to the literature \cite{}, the most popular metrics to analyze are:

\begin{enumerate}

    \item Network throughput, which is the average rate of successful data transfer through a network connection.
    
    \item Latency, which consists in how long a packet takes to travel across a link from one endpoint to another
    
    \item Packet loss, which consists in how many packets are lost when traveling towards their destination.
    
    \item Jitter, which is the variation in latency of packets received sequentially. 
    
\end{enumerate}

\subsection{Aggregation techniques}

Provided that we need to continuously monitor the aforementioned metrics, if we were to store and transmit them directly, the amount of communication and processing needed to do this would make the system unscalable, consequently, in this section study ways to perform \textit{aggregation} over these metrics.

Aggregation consists in the determination of important system wide properties in a decentralized manner \cite{DBLP:journals/corr/abs-1110-0725}, and it is an essential building block towards monitoring distributed systems. Towards monitoring edge devices and tasks running on them, aggregation is paramount, examples of usages are (e.g. computing the average latency of the closest available  service that meets a certain criteria; counting nearby available computing resources that can be used to offload services, or identify hotspots by aggregating the average system load in certain areas).

There are two properties of aggregation functions: \textit{decomposability} and \textit{duplicate sensitiveness}.

\textbf{Decomposability}

For some aggregation functions, we may need to involve all elements in the multiset, however, for memory and bandwidth issues, it is impractical to perform a centralized computation, hence, the aim is to employ \textit{in-transit computation}. In order to enable this, it is required that the aggregation function is \textbf{decomposable}. 

Intuitively, a decomposable aggregation function is one where a function may be composed defined as a composition of other functions. Decomposable functions may \textit{self-decomposable}, which intuitively means that the aggregated value is the same for all possible combinations of all sub-multisets partitioned in the multiset. This happens whenever the applied function is commutative and associative (e.g. min, max, sum, count).

A canonical example of a decomposable function that is not self-decomposable is average, which consists in the sum of all pairs divided by the count of peers that contributed to the aggregation.

The second property of aggregation is \textbf{duplicate sensitiveness}, and it is related to wether a given value occurs several times in a multiset. Depending on the aggregation function used, the presence of repeated values may influence the result, it is said that a function is \textbf{duplicate sensitive} if the result of the aggregation function is influenced by the repeated values (e.g. SUM). Conversely, if the aggregation function is \textbf{duplicate insensitive}, it can be successfully repeated any number of times to the same multiset without affecting the result (e.g. MIN and MAX).

Table \ref{table:aggregation_functions} classifies popular aggregation functions in function of decomposability and duplicate sensitiveness as found in \cite{DBLP:journals/corr/abs-1110-0725}:

\begin{table}[]
    \begin{tabular}{|l|l|l|l|}
    \hline
                          & \multicolumn{2}{l|}{Decomposable} & Non-Decomposable  \\ \hline
                          & Self-decomposable    &                             &  \\ \hline
    Duplicate insensitive & Min, Max             & Range     & Distinct Count    \\ \hline
    Duplicate sensitive   & Sum, Count           & Average   & Median, Mode     \\ \hline
    \end{tabular}
    \caption{popular aggregation functions in function of decomposability and duplicate sensitiveness}
    \label{table:aggregation_functions}
\end{table}

Building on the concepts of duplicate sensitiveness and decomposability, we show that aggregation functions present their own particularities which dictate their applicability in particular scenarios. For example, a Min or Max function may be easier to implement with a simpler algorithm, while Sum, Count and Average require extra considerations. This presents a limitation towards calculating exact aggregations in large scale systems, to circumvent this, some systems do not require obtaining exact aggregated values to perform near optimally  (e.g. estimating the system size in order to select the optimal fanout for a gossip system only requires an estimation of the magnitude of the system). 

\subsubsection{Aggregation techniques}

Following, we present a taxonomy of aggregation techniques for edge devices, for each technique, we provide context and discuss its possible advantages and limitations in the edge environment.

\subsubsection{Hierarchical}

\textbf{Tree-based} approaches leverage directly on the decomposability of aggregation functions. Aggregations from this class depend on the existence of a hierarchical communication structure, (e.g. a spanning tree) with one root (sink node). Aggregations take place by splitting inputs into groups and aggregating values bottom-up in the hierarchy. 

Commonly, hierarchical aggregation systems have nodes whose roles are \textit{aggregators} or \textit{forwarders}, intuitively, aggregators compute the aggregation functions and forward results to forwarders who then retransmit the results to upper levels in the hierarchy. In the absence of faults, the correct final result is obtained in the sink node.

\textbf{Cluster-based} techniques rely on clustering the nodes in the network according to a certain criterion (e.g. latency, energy efficiency). In each cluster a representative is responsible for local aggregation and for transmitting the results to other nodes. 

Hierarchical approaches, due to taking advantage of device heterogeneity, are attractive in edge environments. However, due to the low computational power of devices, not all nodes may be able to handle the additional overhead of maintaining the hierarchical topology.

\subsubsection{Averaging}

Averaging aggregation consists in the continuous computation and exchanging of partial averages data among all active nodes in the aggregation process. In this type of systems, after a few rounds, all nodes usually converge to the correct value with high accuracy, as shown in \cite{gossip_aggregation}.

This type of aggregation is attractive for gossip protocols, where nodes may employ varied gossip techniques to continuously share and update their values with random neighbors.

Algorithms from this category are also attractive to use in edge environments, because they are accurate while employing random unstructured overlays, which retain their fault-tolerance and resilience to churn.

\textbf{Sketches} are fixed-size data structures that hold a \textit{sketch} of all network values. Multiple sketches are usually forwarded throughout the system, and nodes who forward sketches apply (usually commutative and associative) operations to update and merge them. \textcolor{red}{functioning and edge discussion}

% completar funcionamento

\textbf{Digests} are an aggregation technique that gathers a representation of all system values, it supports complex aggregation functions such as Median and Mode. In short, algorithms employ a fixed-size data structures commonly composed of a set of values and associated counters) which compacts the data distribution (e.g. into a histogram). \textcolor{red}{edge discussion}

\textbf{Counting} algorithms target the same aggregation function: Count, algorithms from this class usually employ some randomized procedure to achieve a probabilistic approximation of the population size.

\subsection{Relevant aggregation protocols}

In this subsection we will analyze relevant aggregation protocols that illustrate some techniques discussed above.

\subsubsection{TAG: Tiny AGgregation}

\textbf{TAG: Tiny AGgregation}\cite{Madden2002} is a service for aggregation in low-power, distributed, wireless sensor networks. TAG distributes queries in the network in a time and power-efficient manner by employing a hierarchical aggregation pattern. For each aggregation procedure, there is a \textit{root} nodes which broadcasts a message to start the tree-building process, each message contains two fields: a level and a an ID. Whenever a node without an assigned level receives a tree-building message, it assigns its own level as the message level plus one, and its own parent as the message sender. Then, it reassigns the level and ID to its own and forwards the message to other nodes. Then, whenever a node wishes to send a message to the root, it simply forwards the message bottom-up in the tree. The formed topology allows the computation of Count, Maximum, Minimum, Sum and Average. It is important to notice that the formed tree will be unbalanced as a function of the underlay latency and processing time.

\subsubsection{SingleTree} 

\textbf{SingleTree} \cite{} \textcolor{red}{//TODO}

\subsubsection{MultipleTree} 

\textbf{MultipleTree} \cite{} \textcolor{red}{//TODO}

\subsubsection{DECA} \textbf{DECA} \cite{Artigas2006} \textcolor{red}{//TODO}

\subsection{Monitoring systems}

Following, we study monitoring systems found in the literature, for each system we analyze its advantages and drawbacks followed by a discussion with the system's applicability in an Edge environment,

\subsubsection{Astrolabe}

\textbf{Astrolabe} \cite{Renesse2003} is a platform which aims at monitoring the dynamically changing state of a collection of distributed resources. 

Astrolabe introduces a hierarchical architecture defined by zones, a zone is recursively defined to be either a host or a set of non-overlapping zones. Each zone (minus the root zone) has a local identifier, which is unique within the zone where it is contained, zones are globally identified by their \textit{zone name}, which consists of the concatenation of all zone identifiers within the path from the root to the zone.

Associated with each zone there is a Management Information Base (MIB), which consists in a set of attributes from that zone. Zone attributes are not directly writable, instead, they are generated by aggregation functions contained in special entries in the MIB. Leaf zones are the exception to the aforementioned mechanism, leaf zones contain \textit{virtual child zones} which are directly writable by devices within that virtual child zone.

The aggregation functions which produce the MIBs are contained in \textit{aggregation function certificates} (AFCs), which contain a user-programmable SQL function, a timestamp and a digital signature. In addition to the aforementioned code, AFCs may contain other information. An \textit{Information Request AFC}, in addition to the code, specifies which information to retrieve from each participating host, and how to summarize the retrieved information. Alternatively, we may have a \textit{Configuration AFC} which specifies runtime parameters that applications may use for dynamic configuration.

Astrolabe a employs gossip which provides an eventual consistency model: if updates cease to exist for a long enough time, all the elements of the system  converge towards the same state. This is achieved by employing a gossip algorithm which selects another agent at random and exchanges zone state with it. If the agents are within the same zone, they simply exchange information relative to their zone. Conversely, if agents are in different zones, they exchange information relative to the zone which is their least common ancestor.

Not all nodes gossip information, within each zone, a node is elected (the authors do not specify how) to perform gossip on behalf of that zone, additionally, nodes can represent nodes from other zones, in this case nodes run one instance of the gossip protocol per zone it represents. The number of represented zones is bounded by the number of levels in the Astrolabe tree.

Astrolabe relies on clock time from the devices enforce an order among MIBs. Originally, it compared timestamps contained in MIBs to impose an order among them, however, as the system scaled, this approach is became unreliable. To circumvent this, Astrolabe agents store the last MIB from each agent that gossiped with them, and only compare the timestamps of MIBs which originated from the same representative.

Given this, attribute updates may not be monotonic, this happens due to the fact that aggregations do not take into account the time where the leaf attribute was updated. 

A agents' zone is defined by the system administrator, which is a potential limitation towards scalability, given that configuration errors have the potential to heavily reduce system latency and traffic locality. Additionally, the original authors state that the size of gossip messages scales with the branching factor, often exceeding the maximum size of a UDP packet. 

\subsubsection{Ganglia}

\textbf{Ganglia} is a scalable distributed monitoring system \cite{massie2004ganglia} for high performance computing systems, namely clusters and grids. In short, Ganglia groups nodes in clusters, in each cluster, there are representative cluster nodes which federate devices and aggregate internal cluster state.

Ganglia relies on IP multicast to perform intra-cluster aggregation, it is mainly designed to monitor infrastructure monitoring data about machines in a high-performance computing cluster. Then, it displays the time series data in a Web interface.

As previously mentioned, Ganglia is aimed towards monitoring high-performance 
grids. And its applicability is limited towards edge environments: (1) clusters are situated in stable environments, which contrasts with the edge environment; (2) it relies on IP multicast (which has been proven not to hold in a number of cases) to perform automatic discovery of nodes as they are added and removed within clusters; (3) has no mechanism to prevent network congestion 

\subsubsection{SDIMS}

\cite{10.1145/1030194.1015509} proposes a scalable distributed information management system (SDIMS) which leverages on distributed hash tables to create scalable aggregation trees. \textcolor{red}{completar...}

\subsubsection{Prometheus}

\textbf{Prometheus} \cite{prometheus} is an open-source monitoring and alerting toolkit originally built at SoundCloud. Prometheus works well for recording any purely numeric time series. It supports machine-centric monitoring as well as monitoring of highly dynamic service-oriented architectures. 

Prometheus is especially useful towards querying and collecting multi-dimensional data collections. Furthermore, it offers a platform towards configuring alerts, which are triggered whenever a certain criteria is met.

Prometheus allows a prometheus server to scrape selected time-series from another Prometheus server. This allows deploying scalable monitoring setups or scraping related metrics from another service's Prometheus into another. Prometheus federation is split in two categories, \textit{hierarchical federation} and \textit{cross-service federation} 

In \textit{hierarchical federation}, prometheus servers are organized into a topology which resembles a tree, where each server aggregates aggregated time series data from a larger number of subordinated servers. Alternatively,  \textit{cross-service federation} enables scraping selected data from another service's prometheus server to enable alerting and queries against both datasets within a single server. 

Prometheus employs a variety of service discovery options for discovering and scraping targets, including Kubernetes, Consul, among others. A key feature which improves its flexibility is the option to use file-based discovery,  which enables the use of customized service discovery. This is achieved by programmers by providing a custom file with list of targets (and target metadata) which prometheus will scrape.

\subsubsection{\textcolor{red}{Mais papers sobre monitoring, especialmente na edge}}

\subsection{Discussion}

We believe there is a lack of monitoring systems targeted towards edge environments, in our study of the literature, we did not find many resources regarding monitoring large numbers of heterogenous nodes at a large scale.

Most studied large scale information systems are targeted towards cloud environments, which as previously mentioned contrast immensely with the edge environment. These solutions often rely on techniques such as IP multicast \cite{massie2004ganglia} to perform efficiently.

Furthermore, we argue that large-scale monitoring systems purely based on distributed hash tables \cite{10.1145/1030194.1015509} are unsuitable for edge environments, as  devices are heavily constrained in memory and often are unreliable routers (which a DHT assumes all nodes can reliably do).  Conversely,existing pure gossip systems such as Astrolabe \cite{Renesse2003} require heavy amounts of message exchanges to keep information up-to-date, and require manual configuration of the hierarchical tree.

