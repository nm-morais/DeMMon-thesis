
After studying the taxonomy of the edge environment, it is paramount to study how these devices can execute tasks (e.g. services, monitoring tasks, among others) in a controlled environment. A major requirement of these environments is that tasks interfere as little as possible with other running tasks as well as with the core behavior of the system.

A popular approach towards solving the aforementioned challenges is to perform tasks in loosely coupled independent components running some form of virtualization software, as it enables co-deployment tasks in the same physical node. The main benefits of employing virtualization include hardware independence, isolation, secure user environments, and increased scalability. 

The two most common types of virtualization used nowadays are containers and virtual machines (VMs), in this section present a brief description of both technologies, and study their advantages and limitations towards supporting edge-enabled applications.

\subsection{Virtual Machines}

A VM provides a complete environment in which an operating system and many processes, possibly belonging to multiple users, can coexist. By using VMs, a single-host hardware platform can support multiple, isolated guest operating system environments simultaneously \cite{1430629}. 

Virtual machines rely on a type of software called a \textit{hypervisor}, the role of the hypervisor is to abstract hardware to support the concurrent execution of full-fledged operating systems (e.g. Linux or Windows). This abstraction layer provides great isolation between virtual machines, meaning that a VM cannot directly interact with the host or the other VMs, which is highly desirable for both virtualized applications and the host machine. 

However, virtualizing the hardware and the device drivers incurs an non-negligible overhead, and the large image sizes of operating systems makes live migrations harder to accomplish, which we believe to be crucial in edge environments. Given the aforementioned reasons, we believe that virtual machines are unsuited for edge environments.

\subsection{Containers}

Containers (e.g., Docker \cite{docker}, Linux Containers (LXC) \cite{lxc}, among others) can be considered as a lightweight alternative to hypervisor-based virtualization. When using containers, applications share an OS (and maybe binaries and libraries), and implement isolation of processes at the operating system level. As a result, these deployments are significantly smaller in size than hypervisor deployments, for comparison, a physical machine may store hundreds of containers versus a few tens of VMs \cite{7036275}.  

In terms of performance, container-based virtualization can be compared to an OS running on bare-metal in terms of memory, CPU, and disk usage \cite{preeth2015evaluation}, and contrary to VMS, restarting a container doesn't require rebooting the OS \cite{7036275}, meaning that such a task can be much faster.

Consequently, given their lightweight nature, it is possible to deploy container-based applications (e.g. microservices), which can perform fast migration across nodes in the edge environment (e.g. in order to improve quality of service (QoS) of applications). This flexibility towards the migration process is an effective tool to deal with many challenges such as load balancing, scaling, resource reallocation and fault-tolerance. 

\subsection{Discussion}

Although VMs are widely present in the cloud infrastructure, they have significant start up time (due to having to start-up an entire OS) and the image sizes are larger when compared to containers, which hinders the ability to perform quick migrations across different devices. 

The accumulation of these factors make VMs unsuited for devices with low capacity and availability, which are abundant in edge environments, consequently, we believe containers are the most appropriate solution when it comes to performing resource sharing in edge scenarios. 