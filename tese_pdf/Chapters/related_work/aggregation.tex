
Aggregation is an essential building block on modern distributed systems, it  enables the determination of important system wide properties in a decentralized manner \cite{DBLP:journals/corr/abs-1110-0725}. Aggregation consists in computing an aggregation function over a set of input values where each node has one input value. Common aggregation functions consist in sum, count, average, min, max, where each function presents different properties which must be considered.

Towards deploying services in edge devices, aggregation may be used to monitor the device and service state (e.g. computing the average latency of the closest available service that meets a certain criteria; counting nearby available computing resources that can be used to offload services, or identify hotspots by aggregating the average system load in certain areas). Given this, it is important to understand the challenges of aggregating values in a highly decentralized manner. There are two properties of aggregation functions: \textit{decomposable functions} and \textit{duplicate sensitive} functions.

\subsection{Properties of aggregation functions}

For some aggregation functions, we may need to involve all elements in the multiset, however, for memory and bandwidth issues, it is impractical to perform a centralized computation, hence, the aim is to employ \textit{in-transit computation}. In order to enable this, it is required that the aggregation function is \textbf{decomposable}. Intuitively, a decomposable aggregation function is one where a function may be composed defined as a composition of other functions. Decomposable functions may \textit{self-decomposable}, which intuitively means that the aggregated value is the same for all possible combinations of all sub-multisets partitioned in the multiset. This happens whenever the applied function is commutative and associative (e.g. min, max, sum, count). A canonical example of a decomposable function that is not self-decomposable is average, which consists in the sum of all pairs divided by the count of peers that contributed to the aggregation.

The second property of aggregation is \textbf{duplicate sensitiveness}, and it is related to wether a given value occurs several times in a multiset. Depending on the aggregation function used, the presence of repeated values may influence the result, it is said that a function is \textbf{duplicate sensitive} if the result of the aggregation function is influenced by the repeated values (e.g. SUM), conversely, if the aggregation function is \textbf{duplicate insensitive} it can be successfully repeated any number of times to the same multiset without affecting the result (e.g. MIN and MAX).

Table \ref{table:aggregation_functions} classifies popular aggregation functions in function of decomposability and duplicate sensitiveness as found in \cite{DBLP:journals/corr/abs-1110-0725}:

\begin{table}[]
    \begin{tabular}{|l|l|l|l|}
    \hline
                          & \multicolumn{2}{l|}{Decomposable} & Non-Decomposable  \\ \hline
                          & Self-decomposable    &                             &  \\ \hline
    Duplicate insensitive & Min, Max             & Range     & Distinct Count    \\ \hline
    Duplicate sensitive   & Sum, Count           & Average   & Median, Mode     \\ \hline
    \end{tabular}
    \caption{popular aggregation functions in function of decomposability and duplicate sensitiveness}
    \label{table:aggregation_functions}
\end{table}

Building on the concepts of duplicate sensitiveness and decomposability, we show that aggregation functions present their own particularities which dictate their applicability in particular scenarios. For example, a Min or Max function may be easier to implement with a simpler algorithm, while Sum, Count and Average require extra considerations. This presents a limitation towards calculating exact aggregations in large scale systems, to circumvent this, some systems do not require obtaining exact aggregated values to perform near optimally  (e.g. estimating the system size in order to select the optimal fanout for a gossip system only requires an estimation of the magnitude of the system). 

\subsection{Aggregation techniques}

Following, we present the studied categories of aggregation techniques: Hierarchical, Averaging, Sketches (hash or min-k based), Digests, Deterministic and Sampling. In each technique, we discuss its applicability in the edge environment.

\subsubsection{Hierarchical}

\textbf{Hierarchical} approaches leverage directly on the decomposability of aggregation functions. Aggregations from this class depend on the existence of a hierarchical communication structure, (e.g. a spanning tree) with one root (sink node). Aggregations take place by splitting inputs into groups and aggregating values bottom-up in the hierarchy. Commonly, hierarchical aggregation systems have nodes whose roles are \textit{aggregators} or \textit{forwarders}, intuitively, aggregators compute the aggregation functions forward results to forwarders who transfer results to upper levels in the hierarchy. In the absence of faults, the correct final result is obtained in the sink node. Many systems employ hierarchical approaches to aggregation, namely TAG \cite{}, DAG \cite{}, among others. Hierarchical approaches, due to taking advantage of device heterogeneity, are attractive in edge environments. However, due to the low computational power of devices, not all nodes may be  able to handle the additional overhead of maintaining the hierarchical topology.

\textbf{Averaging} aggregation consists in the continuous computation and exchanging of partial averages data among all active nodes in the aggregation process. In this type of systems, after a few rounds, all nodes usually converge to the correct value with high accuracy, as shown in \cite{gossip_aggregation}. This type of aggregation is attractive for gossip protocols, where nodes may employ varied gossip techniques to continuously share and update their values with random neighbors. Algorithms from this category are also attractive to use in edge environments, because they are accurate while employing random unstructured overlays, which retain their fault-tolerance and resilience to churn.

\textbf{Sketches} are fixed-size data structures that hold a \textit{sketch} of all network values. Multiple sketches are usually forwarded throughout the system, and nodes who forward sketches apply (usually commutative and associative) operations to update and merge them. \textcolor{red}{functioning and edge discussion}

% completar functionamento

\textbf{Digests} are an aggregation technique that gathers a representation of all system values, it supports complex aggregation functions such as Median and Mode. In short, algorithms employ a fixed-size data structures commonly composed of a set of values and associated counters) which compacts the data distribution (e.g. into a histogram). \textcolor{red}{edge discussion}

\textbf{Counting} algorithms target the same aggregation function: Count, algorithms from this class usually employ some randomized procedure to achieve a probabilistic approximation of the population size.

\subsection{Relevant aggregation protocols}

In this subsection we will analyze relevant aggregation protocolsthat ilustrate some techniques discussed above.

\textbf{TAG: Tiny AGgregation}\cite{Madden2002} is a service for aggregation in low-power, distributed, wireless sensor networks. TAG distributes queries in the network in a time and power-efficient manner by employing a hierarchical aggregation pattern. For each aggregation procedure, there is a \textit{root} nodes which broadcasts a message to start the tree-building process, each message contains two fields: a level and a an ID. Whenever a node without an assigned level receives a tree-building message, it assigns its own level as the message level plus one, and its own parent as the message sender. Then, it reassigns the level and ID to its own and forwards the message to other nodes. Then, whenever a node wishes to send a message to the root, it simply forwards the message bottom-up in the tree. The formed topology allows the computation of Count, Maximum, Minimum, Sum and Average. It is important to notice that the formed tree will be unbalanced as a function of the underlay latency and processing time.

\textbf{DECA} \cite{Artigas2006} \textcolor{red}{//TODO}

\textbf{Astrolabe} \cite{Renesse2003} \textcolor{red}{//TODO}

\textbf{SingleTree \cite{} and MultipleTree \cite{}} \textcolor{red}{//TODO}

\subsection{Discussion}