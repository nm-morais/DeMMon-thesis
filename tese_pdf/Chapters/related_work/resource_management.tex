
In this section we study resource management, which consists in providing resources (e.g. computing power, memory, among other) to tenants (i.e. applications, frameworks, among others) such that tenants can perform their tasks. In this section we cover the different types of resource management solutions and study popular implementations in the literature.

\subsection{Resource Management Taxonomy}

A resource management system aims at controlling the distribution of resources among application(s). We may classify resource management architectures according to their \textit{control} and \textit{tenancy}. \textbf{Control} refers to how the resources are provisioned towards applications, whereas \textbf{tenancy} refers to how whether applications share the system resources or not.

\subsubsection{Tenancy}

As previously mentioned, tenancy refers to whether entities share system resources or not. The term tenancy in distributed systems refers to whether or not underlying hardware resources are shared among entities \cite{Hong2019}.

\textbf{Single tenancy} refers to an architecture in which a single instance of a software application and supporting infrastructure serves one customer. In single-tenancy architectures, a customer (tenant) has nearly full control over customization of software and infrastructure. There are many advantages of having single-tenancy architectures such as data security: Even if there is a data breach to one tenant with the same provider, another tenant would be safe from the breach, since the data is stored in a separate instance. However, single tenancy goes against most distributed systems today, which are shared by multiple tenants, both on private and public clouds \cite{mace2015retro}.

\textbf{Multi-tenancy} consists in tenants sharing multiple resources across multiple processes and machines. This approach has clear advantages, as sharing the infrastructure leads to lower costs (e.g. electricity), and companies of all sizes like to share infrastructure in order to achieve lower operational costs. 

However, providing performance guarantees and isolation in multi-tenant systems is extremely hard, resource management systems must avoid mismatching the resource allocation, as tenant-generated requests compete with each other and with the system generated tasks. Furthermore, tenant workload can change in unpredictable ways depending on the input workload, the workload of other tenants in the system and the underlying topology. Given this, mismanaging the system resources may degrade tenant performance and in extreme cases even hinder the stability of the resource management system.

\subsubsection{Control}

Control refers to how resource management systems allocates tasks, there are two alternatives towards performing resource allocations: either centralized or decentralized.

\textbf{Centralized control} consists of a centralized component which has a global view of the state of the system making all decisions regarding resource allocations. Intuitively, given that a centralized component generates manages all the resources in the system, this component can enforce policies which achieve the desired performance guarantees or fairness goals by identifying and only throttling the tenants or system activities responsible for resource bottlenecks \cite{verma2015large}.

Many resource management systems rely on a centralized component having a global view of the system, especially in Cloud environments, where nodes are federated in large clusters of machines with similar computing power. These systems often rely on Zookeeper \cite{hunt2010zookeeper} to maintain the component available and to transfer the controller state to a new controller in case the active one fails.

\textbf{Decentralized control} architectures are those where the the decision-making process is distributed across multiple components \cite{Hong2019}. This topic has yet not been subject to much research, although it is of extreme relevance towards edge environments. For example, if the system is globally distributed, it may take too long for a centralized controller to identify hotspots in a certain zone and load-balance them.

One of the biggest challenges of controlling the resource management in a distributed fashion is ensuring that the components which perform resource assignments do not conflict with each other. Additionally, in a multi-tenant decentralized resource control system, tenants may request resources to different resource controllers in the system, and if they do not coordinate themselves, the application may be provisioned with too many (or too little) resources.

\subsection{Resource Sharing Systems}

\subsubsection{Mesos}

Mesos \cite{hindman2011mesos} is a multi-tenant centralized resource sharing platform which attempts to provide fine-grained resource sharing in the Data Center. The tenants for this platform are frameworks such as HDFS \cite{borthakur2008hdfs}, MapReduce \cite{dean2008mapreduce}, among others, which in turn support multiple applications running in the DC.

In short, the Mesos resource sharing system consists of a \textit{master} process which manages \textit{slave} daemons running on each cluster node, in order to achieve fault-tolerance for the master component, Mesos employs Zookeeper \cite{hunt2010zookeeper} to elect a new master and transfer state to a new master if the active master crashes.

The master node implements fine-grained sharing of resources across frameworks by employing \textit{resource offers}, which consist of lists of free resources distributed among slaves. Resource offers provide flexibility for frameworks operating on Mesos, given that each framework has different communication patterns, task dependencies and data placement, a centralized scheduler would need to provide an extremely expressive API to capture all frameworks' requirements. 

Instead, the master makes decisions about how many resources to offer to each framework, and its decision-making process is based on an arbitrary organizational policy, such as fair sharing or priority. Each framework that wishes to use Mesos must implement \textit{scheduler} and an \textit{executor}, the scheduler registers with the Mesos master to receive resource offers, and the executor is the process that is launched on slave nodes to run the framework's tasks.

A limitation of the Mesos resource sharing platform is that it is not scalable (the original authors mention the system scales up to 50000 slave daemons on 99 physical machines), which is not enough for an edge environment. Furthermore, the resource offer model forces frameworks to employ a specific programming model based on schedulers and executors, which may not be desirable by the framework author, and finally, we argue that in an edge environment, the centralized master would not be able to process all resource requests and provide timely resource offers in a large-scale system.

\subsubsection{Yarn}

Yarn (Yet Another Resource Negotiator) \cite{Vavilapalli2013ApacheHY} is a centralized multi-tenant resource sharing platform which attempts decouple the programming model from the resource management infrastructure, and delegate many scheduling functions to per-application components. 

The architecture of YARN is as follows: the system is composed of a per-cluster Resource Manager (RM), multiple Application Masters (AM) and Node Managers (NM). 

The Resource Manager (RM) tracks resource usage and node liveness, enforces allocation invariants and arbitrates contention among tenants. It matches a global model of the cluster state against the digest o resource requirements reported by the applications, which allows the RM to tightly enforce global scheduling properties such as capacity or fairness.

The Application Master (AM) runs arbitrary user code, and can be written in any programing language, its duties in the system consist of managing the lifecycle aspects including dynamically increasing and decreasing resource consumption, managing the flow of execution and handling faults. 

The Node Manager (NM) is the worker daemon in YARN. Its responsibilities in the system consist of managing container dependencies, monitor their execution and provide a set of services for containers. 

AMs send resource requests to the RM, these contain the number of containers to request, the resources per container, locality preferences and a priority level within the application. Resource requests are designed to capture the needs of applications, while at the same time removing specific application concerns (such as task dependencies) from the scheduler.

The resource request model effectively makes YARN RM a \textit{monolithic} scheduler, because the RM is in charge of processing and scheduling all task distributions for each request made by AMs. This contrasts with MESOS \cite{hindman2011mesos}, which delegates task scheduling for the frameworks. Given this, its limitations are similar to Mesos, given the centralized point of failure.

%\subsubsection{Omega}

\subsubsection{ENORM}

Edge NOde Resource Management \cite{wang2017enorm} (ENORM) framework aimed at employing edge resources towards applications by provisioning and auto-scaling edge node resources. It attempts to answer these two questions: "How to deploy a workload on the edge node?"\ and "How much of the workload can be deployed on the edge node?".

ENORM proposes a three-tier architecture: (1) the Cloud tier, where application servers are hosted; (2) the middle tier, where the edge nodes are situated; (3) the bottom tier, where user devices (e.g. smartphones, wearables, gadgets) are situated. 

To enable the use edge nodes, ENORM deploys a \textit{cloud server manager} on each application server which communicates with potential edge nodes requesting computing services, deploys partitioned servers on the edge nodes, and finally receives updates from the edge nodes to update the global view of the application server on the cloud.

Each edge node is composed by the following 5 components: (1) \textit{Resource Allocator} which provides computing as a service, this is the basic service of the edge node, and cannot be compromised, which means that it has priority over offloaded computations; (2) \textit{Edge Manager} deals with the requests that are obtained by the server manager in the cloud, and once a request is successful, it initializes a container and allocates the necessary ports for communication; (3) \textit{Monitor} which periodically reports a number of metrics related to the application running on the edge server (e.g. communication latency and computing latency); (4) \textit{Auto-scaler} dynamically allocates and de-allocates hardware resources to the container executing application servers. It is responsible for scaling the process such that the application can accommodate a larger number of users. (5) \textit{Application Edge Server} the partitioned server which is hosted on the edge node.

ENORM authors test the designed system using an online game based on Pokemon GO (iPokemon)\cite{pokemonGo}, the framework partitions the game server and sends  user data relevant to the geographical location of the edge node. Users from the relevant geographical zone connect to the edge server and are serviced as if they were connected to the data center. 

Limitations from this framework are similar to Mesos and Yarn, specifically lack of fault-tolerance and scalability, which arise from a centralized component monitoring and managing all the edge nodes at the same time. 

\subsection{Discussion}

Although resource management systems have been present for many years, these are often tailored towards small scale environments composed by high-capacity devices in stable environments, which contrast with the edge of the network, where devices are extremely numerous, decentralized, and heterogenous.

We argue that a centralized controller isn't the ideal solution for an edge environment, given the fact that as the number of devices in the system increases, so does the number of resources to track, and the harder it is for a centralized component to have an up-to-date global view of the system. 

This occurs because the edge environment is heavily decentralized, which means that monitoring information takes a long time to propagate to the centralized component, or because there is not enough computing power or memory to handle all the information in a centralized component.

In addition, due to their low capacity, devices in the edge of the network are very susceptible to workload changes, for example, a 5G tower which is hosting a service cannot handle a drastic increase in the number of users it is servicing. In this scenario, we argue that in order to maintain QoS, devices must autonomously make resource management decisions such as scaling horizontally or vertically in order quickly meet the demands of users.

% \subsubsection{Scheduling}

% There are many approaches towards scheduling resources among edge nodes: \textbf{Brute force} proposes exhaustively exploring all potential targets combinations towards offloading tasks (including the Cloud, the Edge and other user devices) and picking the one which provides the minimum execution time. This technique intuitively is not scalable enough to be applied in practice.

% \textbf{Greedy} heuristics focus on minimizing the time it takes for the task to be completed on a mobile device. FogTorch \cite{Brogi2017} employs a greedy heuristic by which reduces the search space of devices that constitute options for service deployments. 

% \textbf{Simulated Annealing} employs a search space based on the utilization of edge and cloud nodes, total costs, and the completion time of the task to find the optimal solution.

% \subsubsection{Offloading}

%In this section we study offloading, which is technique used by edge-enabled applications to fully take advantage of edge nodes.

%Offloading is a technique in which a server, application and the associated data are transferred onto another node in the network \cite{Hong2019}. There are two variants for offloading: either from the user device to the edge, or from the cloud to the edge. 

%Offloading from user device to the edge enhances computing in mobile nodes by employing edge nodes which are usually only one or two hops away. While offloading from the Cloud to the edge has the potential to reduce bandwidth consumption and improve QoS of edge-enabled applications. 

%\textbf{Server offloading} is a technique in which servers are offloaded to the edge via either replication or partitioning. \textbf{Replication} consists in offloading the full server state(e.g. a database or an  application server), while \textbf{partitioning} consists in offloading only a portion of the server state. 

%The portion of the server to offload must take into account a set of parameters such as latency, functionality, energy efficiency, geographical distribution, among others. 

