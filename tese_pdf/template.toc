\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\babel@toc {english}{}
\babel@toc {portuguese}{}
\babel@toc {portuguese}{}
\babel@toc {portuguese}{}
\babel@toc {portuguese}{}
\babel@toc {portuguese}{}
\babel@toc {portuguese}{}
\babel@toc {portuguese}{}
\babel@toc {english}{}
\babel@toc {portuguese}{}
\babel@toc {english}{}
\babel@toc {portuguese}{}
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\chapternumberline {1}Introduction}{1}{chapter.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {1.1}Context}{1}{section.1.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {1.2}Motivation}{2}{section.1.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {1.3}Expected Contributions}{3}{section.1.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {1.4}Thesis structure}{3}{section.1.4}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\chapternumberline {2}Related Work}{5}{chapter.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.1}Resource Location}{5}{section.2.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {paragraph}{ \textbf {Centralized} architectures rely on one (or a group of) centralized peers that index all resources in the system. This greatly reduces the design of the system, however, it is not scalable and, as the name indicates, it has a centralized point of failure. Some systems use a combination of architectures, such as using a centralized service to provide infrastructure for a DHT overlay. Some applications have employed this architecture with success, such as BitTorrent, for serving torrent files through HTTP.}{6}{section*.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {paragraph}{ \textbf {Distributed Hash Tables} are alternatives to centralized servers, where the index distribution is split among peers in the system. Peers map resources to nodes in the system and employ routing algorithms to transverse the topology in a bounded number of steps. Then, using hash functions to map resources (files, multimedia, messages, etc.) to the peer identifier space, and assigning a key-space interval to each peer, peers can find any resource in a bounded number of steps (Exact resource location).}{6}{section*.4}% 
\defcounter {refsection}{0}\relax 
\contentsline {paragraph}{ \textbf {Unstructured Overlays} are the third common approach to resource location systems, in this overlay, each peer will maintain a local index of its own resources and in some cases information of indexes of other peers. Participants then disseminate queries to find sets of nodes that own matching resources.}{6}{section*.5}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.1.0.1}Distributed Hash tables}{6}{subsubsection.2.1.0.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {paragraph}{ \textbf {Chord} \cite {stoica2003chord} is a distributed lookup protocol that addresses the need to locate the node that stores a particular data item, it specifies how to find the locations of keys, how nodes recover from failures, and how nodes join the system. Chord assigns each node and key an m-bit identifier that is uniformly distributed in the id space (peers receive roughly the same number of keys). Peers are ordered by identifier in a clockwise circle, then, any key \(k\) is assigned to the first peer whose identifier is equal or follows k in the identifier space. Additionally, Chord implements a system of "shortcuts"\ called the \textbf {finger table}. The finger table contains at most \(m\) entries, each $ith$ entry of this table corresponds to the first peer that succeeds a certain peer \(n\) by \(2^{ith}\) in the circle. This means that whenever the finger table is up-to-date, lookups only take logarithmic time to finish. }{7}{section*.6}% 
\defcounter {refsection}{0}\relax 
\contentsline {paragraph}{ \textbf {Pastry} \cite {rowstron2001pastry} is a DHT that assigns a 128-bit node identifier (nodeId) to each peer in the system. The nodes are randomly generated thus uniformly distributed in the 128-bit nodeId space. Nodes store values whose keys are also distributed in the nodeId space. Key-value pairs are stored among nodes that are numerically closest to the key. This is accomplished by: in each routing step, messages are forwarded to nodes whose nodeId shares a prefix that is at least one bit closer to the key. If there are no nodes available, Pastry routes messages towards the numerically closest nodeId. This routing technique accomplishes routing in O(log N), where N is the number of Pastry nodes in the system. This protocol has been widely used and tested in applications such as Scribe \cite {10.1007/3-540-45546-9_3} and PAST \cite {990064}. Limitations from using Pastry arise from the use of a numeric distance function towards the end of the routing process, which creates discontinuities at some node ID values, and complicates attempts at formal analysis of worst case behavior. }{7}{section*.7}% 
\defcounter {refsection}{0}\relax 
\contentsline {paragraph}{ \textbf {Kademlia} \cite {10.1007/3-540-45748-8_5} is a DHT with provable consistency and performance in a fault-prone environment. Kademlia nodes are assigned 160-bit identifiers uniformly distributed in the ID space. Peers route queries and locate nodes by employing a XOR-based distance function that is symmetric and unidirectional. Each node in Kademlia is a router whose routing tables consist of shortcuts to peers whose \textbf {xor distance} is between \(2^{i}\) by \(2^{i + 1}\) in the ID space. Intuitively, and similar to Pastry, "closer" nodes are those that share a longer common prefix. The main benefits that Kademlia draws from this approach are: nodes learn routing information from receiving messages, there is a single routing algorithm for the whole routing process (unlike Pastry) which eases formal analysis of worst-case behavior. Finally, Kademlia exploits the fact that node failures are inversely related to uptime by prioritizing nodes that are already present in the routing table. }{7}{section*.8}% 
\defcounter {refsection}{0}\relax 
\contentsline {paragraph}{ \textbf {Kelips} \cite {gupta2003kelips} exploits increased memory usage and constant background communication to achieve O(1) lookup time and message complexity. Kelips nodes are split in $k$ affinity groups split in the intervals [0,$k-1$] of the ID space, thus, with $n$ nodes in the system, each affinity group contains $\frac {n}{k}$ peers. Each node stores a partial set of nodes contained in the same affinity group and a small set of nodes lying in foreign affinity groups. Through increased communication cost by employing Gossip protocols and memory consumption (O($\sqrt {n}$) assuming a proportional number of files and peers in the system and a fixed view of nodes in foreign affinity groups), Kelips achieves O(1) time and message complexity in lookups. However, system scalability is limited when compared to Pastry, Chord or Kademlia. }{8}{section*.9}% 
\defcounter {refsection}{0}\relax 
\contentsline {paragraph}{ \textbf {Tapestry} \cite {tapestry} Is a DHT similar to pastry where messages are incrementally forwarded to the destination digit by digit (e.g. ***8 -> **98 -> *598 -> 4598). Lookups have logb(n) time complexity where b is the base of the ID space. A system with n nodes has a resulting topology composed of n spanning trees, where each node is the root of its own tree. Because nodes assume that the preceding digits all match the current node's suffix, it only needs to keep a constant size of entries at each route level. Thus, nodes contain entries for a fixed-sized neighbor map of size b.log(N). }{8}{section*.10}% 
\defcounter {refsection}{0}\relax 
\contentsline {paragraph}{\textbf {Viceroy} }{8}{section*.11}% 
\defcounter {refsection}{0}\relax 
\contentsline {paragraph}{\textbf {Koala} }{8}{section*.12}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.1.1}Unstructured overlays}{8}{subsection.2.1.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {paragraph}{\textbf {Hyparview} \cite {Hyparview} is a protocol that takes a hybrid approach to membership}{9}{section*.13}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.1.1.1}Self-adapting overlays}{9}{subsubsection.2.1.1.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.1.2}Hybrid Approaches}{9}{subsection.2.1.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {paragraph}{\textbf {Curiata}}{9}{section*.14}% 
\defcounter {refsection}{0}\relax 
\contentsline {paragraph}{\textbf {Build One Get One Free}}{9}{section*.15}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.2}Aggregation}{10}{section.2.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.2.1}Types of aggregation}{10}{subsection.2.2.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.2.2}Relevant aggregation protocols}{10}{subsection.2.2.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.3}Offloading computation to the edge}{10}{section.2.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.3.0.1}Decentralizing clouds}{10}{subsubsection.2.3.0.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.3.0.2}Fog Computing}{10}{subsubsection.2.3.0.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.3.0.3}Edge Computing}{10}{subsubsection.2.3.0.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.3.0.4}Osmotic Computing}{10}{subsubsection.2.3.0.4}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.4}Resource and Service Management}{10}{section.2.4}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.5}Aggregation}{10}{section.2.5}% 
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.5.0.1}Membership in P2P systems}{10}{subsubsection.2.5.0.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.6}Resource Discovery}{11}{section.2.6}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.7}Offloading computation to the Edge}{11}{section.2.7}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\chapternumberline {3}Proposed Solution}{13}{chapter.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.1}Document Structure}{13}{section.3.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\chapternumberline {4}Planning}{15}{chapter.4}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.1}Proposed solution}{15}{section.4.1}% 
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.2}Scheduling}{15}{section.4.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{Bibliografia}{17}{section*.17}% 
\defcounter {refsection}{0}\relax 
\contentsline {appendix}{\chapternumberline {A}Appendix 2 Lorem Ipsum}{19}{appendix.A}% 
\defcounter {refsection}{0}\relax 
\contentsline {appendix}{\chapternumberline {I}Annex 1 Lorem Ipsum}{21}{annex.A}% 
