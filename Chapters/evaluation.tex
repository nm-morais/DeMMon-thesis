%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% evaluation.tex
%% NOVA thesis document file
%%
%% Chapter with lots of dummy text
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\typeout{NT FILE evaluation.tex}

\chapter{Evaluation}
\label{cha:evaluation}

In this chapter, it is our goal to demonstrate the applicability of the devised solution through the comparison of multiple aspects of the framework against popular baseline solutions from the literature. To this end, section \ref{sec:exp_setting_conf} covers the experimental setting and configuration in which these comparisons were conducted, namely the execution environment, the specifications of the nodes executing the tests, among other aspects of the experimental setting. Following, in section \ref{sec:overlay_proto_eval}, we provide the obtained results from the conducted experiments testing the applicability of the devised protocol against state-of-the-art baselines. We compare these baselines with our protocol both in their capacity to create and establish the network and in their capacity to perform information dissemination. Lastly, section \ref{sec:agg_proto_eval} covers the experimental evaluation of the implemented aggregation protocol, notably, which solutions composed the baseline for comparison, which experiments were carried, and the obtained results.

\section{Experimental Setting} \label{sec:exp_setting_conf}

To conduct the experimental evaluation of the devised solution against state-of-the-art baselines, instead of resorting to simulation, we implemented those solutions and tested them in an emulated network that aims to be as similar as possible to real-world scenarios. Provided that scalability is one of the components we aimed to test, and there is a limited pool of individual machines in our testbed to conduct the experiments, we resorted to using containerization. Containers allowed us to execute multiple independent processes in a single physical node while still being an isolated environment that allowed the manipulation of the networking conditions of each process. 

As containers are running in different machines, without any additional software, a container from a machine would not be able to communicate with containers executing in a different machine. To overcome this, we made use of Docker \cite{docker} containers and employed a tool called docker swarm \cite{docker-swarm}. This tool allows users to coordinate sets of nodes running Docker. Nodes in a swarm, among many other features, may perform Multi-host networking, which consists in integrating the containers executing among nodes running into a unified network. In this network, containers are automatically assigned IP addresses and can communicate with each other, regardless of the physycal machine each container is executing on. To bootstrap the experimental scenario, we developed a set of scripts in both BASH, Python and GO to create, orchestrate, and decommission containers to run the experiments.

\subsection{Node capacity and connection delays}

As previously mentioned, in order to emulate a real-world scenario where nodes have limited capacity and their connections have delays, there was the need to apply these constraints. Furthermore, it is important to set up these delays realistically. To do so, we used data from real-world readings of real-world scenarios obtained from WonderNetwork \cite{wondernetwork}, which consists in a network composed of 252 nodes spread across 88 countries in 6 continents. This network provides, in addition to node metadata (city, country, among others), a set of latency measurements from each node to every other in the network (including themselves), which we used to setup the latency delays between the containers. As there was the need to test the framework with larger network sizes (of up to 750 nodes), the data points from this network were multiplied by five times. 

Then, as the obtained data from this network did not contain bandwidth information for each node, we used the metadata provided by WonderNetwork, namely the country, to assign bandwidth values according to the list of bandwidth per country provided by speedtest.net \cite{speedtest_global_index}. Provided the purpose of this framework is to perform on cloud-edge scenarios, composed by nodes inside and outside of the data-centre (DC), where nodes outside the DC have lower networking capacity comparatively to nodes running inside the DC, we divided each data point by 12x (to represent the edge nodes running outside of the DC), and divided the first N nodes by 2.5x, (corresponding to the number of data centres).

% Provided with the networking capacity and the latency matrix for all connection pairs, there was the need to both

To limit the networking capacity and inject latency in the containers executing the protocols for the experiments, we used a tool called Traffic Control (TC) \cite{tc_man_page}. This tool is a traffic shaping tool that performs shaping, scheduling, policing and dropping of network packets through the configuration of the kernel packet scheduler. 

% This tool sets up queuing systems and mechanisms by which packets are received and transmitted. 
% then queue (also denominated qdisc) or class specific policies decide which (and whether) packets to accept at what rate on the input of an interface and determining which packets to transmit in what order at what rate on the output of an interface. 

In our case, we used this tool to limit both the available inbound/outbound bandwidth on the container interfaces and to inject delays in all connection pairs. In order to limit the available bandwidth, we used hierarchical token buckets (HTB), which are classful queueing disciplines that employ a complex token-borrowing system to ensure the shaping of traffic according to a (configurable) rate. HTB requires programmers to set up a hierarchical class structure, where child classes, attached to a queue (or qdisc), manipulate packet order and apply rate limiting policies according to configuration.

For our benchmark, we made use of rate-limiting policies, which employ a token borrowing mechanism that functions in the following manner: whenever a certain child class reaches the maximum of its rate, it borrows tokens (up to its \textbf{ceiling} value) from the parent class (if there is a parent class, and that class has available tokens). If the parent class is also limited, then the sum of its child classes will be limited to the parent rate. 

For our experimental configuration, each container creates two default qdiscs, attached to the inbound and outbound networking interfaces. Then, two HTBs are attached to these qdiscs and set up with the respective inbound and outbound bandwidth rate. After this, for both the outbound and inbound classes, two child classes are installed: one intended for latency measurements and keepalive traffic (specific UDP traffic on a pre-configured port); and the other for the remaining traffic. The inbound and outbound classes responsible for measurement traffic are assigned a fixed rate of 500kb, and the inbound and outbound default traffic classes are assigned the remaining rate for the container (according to speedtest.net) minus the 500kb rate for the measurements class. Then, for all the outbound classes (measurement and default traffic), we set up another set of HTB classes for each other container with a very low rate of 6kb and ceiling rate corresponding to the parents' class. This setup forces child classes to borrow tokens from the parent class and be limited by its bandwidth rate.

For each of these leaf classes, we attached a netem qdisc. This qdisc applies a delay to each packet according to the latency measurements taken from WonderNetwork. To route packets from one qdisc to the other, we use filters: in the case of the measurement traffic, the filtering was performed via installing a high-priority filter that verifies the source and destination ports of the packets and sends it to the measurement classes. The remaining traffic is forwarded to the default traffic class via a lower priority filter with no restrictions. After this, the routing from these two outbound classes to the leaf classes is performed via filters observing the destination IP address of the packets and redirecting them to their corresponding netem qdiscs.  The objective of separating the traffic into two distinct classes with their own bandwidth values is to prevent cases where the applicational traffic is high (i.e. testing information dissemination) and the delay caused by the high usage of the data channels would interfere with the measurement packets, leading to incorrect latency measurements and consequent instability during experiments for both DeMMon and the baseline overlay protocols that optimize the overlay. 

Experiments presented in this work were carried out using the Grid'5000 testbed, supported by a scientific interest group hosted by Inria and including CNRS, RENATER and several Universities as well as other organizations (see https://www.grid5000.fr). The hardware from this testbed used to carry the experiments consisted in sets of 10 physical nodes for the experiments with 50 and 250 logical nodes and sets of 30 physical nodes for experiments with both 500 and 750 logical nodes. Each of these physical machines is equipped with 2 x Intel Xeon E5-2630 v3 and 128 GiB of RAM and is executing Linux Debian version 4.19.104-2 and Docker version 20.10.7. The results were obtained through logging the relevant aspects of the experiment to disk and then processing the obtained logs to extract the intended information posterior to the end of the experiments.

Provided with the experimental setup, we now explain the steps taken and the results obtained for the DeMMon framework evaluation.

\section{Overlay Protocol} \label{sec:overlay_proto_eval} \input{Chapters/evaluation/memb_proto_evaluation.tex}

\section{Aggregation Protocol} \label{sec:agg_proto_eval} \input{Chapters/evaluation/agg_proto_evaluation.tex}

\section{Summary}

In this chapter, we studied, through experimentation, the applicability of the devised decentralized aggregation and information dissemination framework, named DeMMon. We began by providing the system model in which we tested our solution (section \ref{sec:exp_setting_conf}), which aims to emulate a realistic cloud-edge scenario composed of nodes with heterogenous networking capacity and distributed among multiple places of the globe. Following, in section \ref{\label{sec:overlay_proto_eval}, we provide the obtained results from the experimental evaluation of the developed membership protocol. In this section, we tested the applicability of this protocol in its capacity to build a latency-optimized network by comparing it with implementations of state-of-the-art baselines in realistic scenarios with multiple node counts and failures. We showed that the implemented protocol is fault-tolerant (within its system model), and although its latency total is not the lowest, if only accounting for its most heavily used connections (the parent connections in the tree), then its total cost is the lowest. While still in this section, we evaluated the information dissemination capabilities of the devised protocol against the same baseline protocols, paired with two dissemination protocols: a simple flood protocol and PlumTree. Overall, we showed that our protocol is a competitive alternative in this regard, as in our tests, it performed better than PlumTree when paired with any baseline membership protocols in all conditions and performed better in lower node counts across all conducted scenarios.

Finally, we concluded the chapter with section \ref{sec:agg_proto_eval}, where we validated the implemented monitoring primitives and compared the obtained results against multiple configurations of a popular baseline solution: Prometheus. We showed that the devised decentralized monitoring solution obtains results comparable to those obtained by Prometheus, and that it provides a higher degree of fault-tolerance, as it does not require manual configuration to recover from failures. 