
In this section, we study the taxonomy of the devices which materialize edge environments and analyze, according to the literature, which computations each device can perform.

% In this Section we provide context about edge-related paradigms, study the taxonomy of the devices which materialize edge environments, and analyze which computations each device can perform.

% \subsection{Edge Computing}

% As previously mentioned, edge computing calls for the processing of data (and potentially storage) across all the devices which act as an "edge"\ along the path from the data center (DC) do the data source or client device~\cite{Leitao2018}. It has the potential of enabling novel edge-enabled applications along with optimizing existing systems~\cite{7488250}, making them more responsive.

%\begin{itemize}

%
%    \item \textbf{Reducing the amount of traffic}, Edge Computing has the potential to reduce the amount of data exchanged between the Edge and the Cloud. For example, in the case of a smart home which computes the average home temperature in all divisions, almost all the data collected by the sensors can be aggregated (averaged) in a home gateway, effectively summarizing the data from a set of values to a single value, which is then sent to the Cloud pre-processed. Reducing the size of the data effectively improves transmission reliability and reduces infrastructure cost for both users and application / cloud operators. 
%    
%    \item \textbf{Reducing Latency} is one of the most important benefits, especially towards time-critical applications (e.g. traffic monitoring) which have special latency needs. Latency consists in the time it takes for a packet to travel the network from the origin endpoint to the target endpoint. Edge computing proposes to improve this by, for example, transferring the computation to the edge node closest to the data requests.
%
%    \item Facilitating new approaches of \textbf{load-balancing}, given that there is a massive increase of devices in the edge of the network, applications may load-balance themselves by offloading tasks towards the nearest available device with enough capacity, or by migrating an entire application towards a nearby device with higher capacity.
%    
%    \item \textbf{Minimizing energy consumption}, edge computing has the potential of optimizing the resource distributions towards saving energy. For example, a device which has low battery but belongs to time-critical service can chose to offload any unnecessary computations towards neighbors as a cost-saving measure. 
%    
%\end{itemize}

% Many approaches have already leveraged on some form of Edge computing in the past. \textbf{Cloudlets}~\cite{10.1145/2307849.2307858} are an extension of the cloud computing paradigm beyond the DC, and consist in deploying resource rich computers near the vicinity of users that provide cloud functionality. They have become a trending subject and have been employed towards resource management, Big Data analytics, security, among others. A limitation of Cloudlets is that because they are specialized computers, they cannot guarantee low-latency ubiquitous service provision, and cannot ensure that applications behave correctly in the presence of large hotspots of users.  

% \textbf{Content Distribution networks}~\cite{peng2004cdn} are specialized high bandwidth servers strategically located at the edge of the network which replicate content from a certain origin and serve it at reduced latencies, effectively decentralizing the content delivery. 

% \textbf{Fog Computing}~\cite{bonomi2012fog} is paradigm which aims at solving similar problems to the Edge Computing. It proposes to provide computing, storage and networking services between end devices and traditional cloud DCs, typically, but not exclusively located at the edge of the network. We consider Fog Computing to be interchangeable with our definition of Edge Computing, however, with a special emphasis on providing infrastructure for edge-enabled services, instead of focusing on the inter-cooperation among devices.

% \textbf{Osmotic Computing}~\cite{villari2016osmotic}  envisions the automatic deployment and management of inter-connected microservices deployed over a seamless infrastructure composed of both edge and cloud devices. This is accomplished by employing an orchestration technique similar to the process of "osmosis". Translated, this consists in dynamically detecting and resolving resource contention via the execution of coordinated microservice deployments / migrations across edge and cloud devices. This paradigm is a subset of Edge Computing, as it only focuses on deploying microservices on edge devices instead of employing them towards generic computations, in addition, the original authors only envision deploying services over cloud and edge DCs, instead of the whole range of possible devices.

% \textbf{Multi-access edge computing}~\cite{mobile_edge_cloud} (MEC) is a network architecture which proposes to provide fast-interactive responses for mobile applications. It solves this by employing the devices in the edge (e.g. base stations and access points) to provide compute resources for latency-critical mobile applications (e.g. facial recognition). Similar to Osmotic Computing, we consider MEC a subset of edge computing, given that its primary focus is on how to offload the computation from mobile to the cloud and not vice-versa. 

\subsection{Edge Environment Taxonomy} \label{subsec:edge_taxonomy}

According to \textcite{Leitao2018}, edge devices may be classified according to three main attributes: \textbf{capacity} refers to computational, storage and connectivity capabilities of the device,  \textbf{availability} consists in the probability of a device being reachable, and finally, \textbf{domain} characterizes the way in which a device may be employed towards applications, either by performing actions on behalf of users (user domain) or performing actions on behalf of applications (applicational domain). Given that the concern of our work is towards building the underlying infrastructure for these applications, we will only focus on capacity and availability when classifying the taxonomy of the environment. 

\begin{table}[!htb]
    \caption{Taxonomy of the edge environment}
    \begin{minipage}{.45\linewidth}
        \centering
        \resizebox{\columnwidth}{!}{%
        \begin{tabular}{|l|l|l|l|}
            \hline
            Level & Category & Availability & Capacity \\ \hline
            L0 & Cloud Data Centers & High & High \\ \hline
            L1 & ISP, Edge \& Private DCs & High & High \\ \hline
            L2 & 5G Towers & High & Medium \\ \hline
            L3 & Networking devices & High & Low \\ \hline
        \end{tabular}}
    \end{minipage} %
    \begin{minipage}{.45\linewidth}
        \centering
        \resizebox{\columnwidth}{!}{%
            \begin{tabular}{|l|l|l|l|}
                \hline
                Level & Category & Availability & Capacity \\ \hline
                L4 & Priv. Servers \& Desktops & Medium & Medium \\ \hline
                L5 &Laptops & Low & Medium \\ \hline
                L6 &Mobile devices & Low & Low \\ \hline
                L7 &Actuators \& Sensors & Varied & Low \\ \hline   
        \end{tabular}}
    \end{minipage} 
    \label{tab:taxonomy_edge}
\end{table}

Table~\ref{tab:taxonomy_edge} shows the proposed categories of edge devices, we assign levels to categories as a function of their distance from the cloud infrastructure. 

\textbf{Levels 0 and 1}, composed of \textit{cloud and edge DCs}, offer pools of computational and storage resources which can dynamically scale. Both of these options have high availability and large amounts of storage and computational power, as such, there is no limitations on the kinds of computations these devices can perform.

\textbf{Levels 2 and 3} are composed of \textit{networking devices}, namely 
\textit{5G cell towers}, \textit{routers}, \textit{switches}, and \textit{access points}. Devices in both levels have high availability, and can easily improve the management of the network, for example, by manipulating data flows among different components of applications (executing in different devices).

\textbf{Levels 4 and  5} consist of \textit{private servers}, \textit{desktops} and \textit{laptops}, devices in these levels level have medium capacity and medium to low availability. They can perform a varied amount of tasks on behalf of devices in higher levels (e.g. compute on behalf of smartphones, act as logical gateways or just cache data). 

\textbf{Levels 6} consists of \textit{tablets} and \textit{mobile devices}, which have low capacity, availability, and short battery life. Given this, they are limited in how they can perform contribute towards edge applications. Aside from caching user data, they may filter or aggregate of data generated from devices in level 7.

Finally, \textbf{level 7} consists of \textit{actuators, sensors} and \textit{things}, these devices are the most limited in their capacity, and enable limited forms of computation in the form of aggregation and filtering.

\subsection{Discussion}

Coincidently, the levels are correlated to the number of devices and their computational power, where higher levels tend to have more devices that are closer to the origin of the data while having lower computational power. Consequently, the higher the level, the harder it is to employ edge devices to support the execution of edge-enabled applications. 

We believe the low availability and potential mobility of devices in higher levels make them unsuitable, as they could potentially be a source of instability in the system. Consequently,  we believe only devices in levels 0-5 are potential candidates to integrate the system we intend to build, provided the remaining devices tend too low of an availability to be possible targets to, for example, host a service reliably. It is, however, important to mention that employing devices in other levels as gateways for those devices can help circumvent this limitation. Hence, starting to establish a natural hierarchy on the way different application components interact and how information (calls or events) flow in such complex systems.
