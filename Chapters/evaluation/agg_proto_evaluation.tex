

In this section we present and analyze the obtained results from the experimental evaluation of the devised decentralized aggregation protocol when compared with a popular monitoting solution from the state of the art, named Prometheus \todo{cite}. We begin by providing the experimental setting and configuration settings used across the conducted experiments, then, we present and discuss the obtained results from these experiments, and finish the section by providing a summary along with the drawn conclusions from the evaluation of our solution in its aggregation capacity.

The experimental setting in which the evaluation of our aggregation protocol was conducted on is the same as the one defined in \ref{sec:exp_setting_conf}, where each solution is tested using containers to multiplex the physical nodes, isolate the running processes, and apply both bandwidth capacity constraints and latency delays.

As previously mentioned in section \ref{sec:mon_protocol}, the devised aggregation protocol offers three decentralized information collection primitives: neighbourhood, tree and global aggregation. In this section, we will provide the obtained results regarding the applicability of each of these features, however, as Prometheus does not provide a comparable feature to the implemented neighborhood aggregation feature, this feature will be tested in an isolated manner. For all the conducted experiments, we tested the systems by collecting a certain aggregated value, calculated through the aggregation of a variable number of metrics, emitted at configurable intervals by dummy applications running in all the nodes of the system. The main criteria used to test the applicability of our solution was its error over time: obtained by comparing the aggregated value obtained by each node against their ``supposed'' value, according to the following formula: 

\[ Error(t) =  \frac{|\sum localVal_i(t) - aggVal(t)|}{\sum localVal_i(t)}\]

, where $localVal_i$ corresponds to the emitted value of each node locally, $\sum localVal_i$ corresponds to the ``supposed'' value and $aggVal$ corresponds to the obtained aggregated value during the experiment. In addition to the error over time, we collected other metrics to acess the performance of our solutions such as the consumption of networking and computing resources. All tests were conducted with network sizes of 750 logical nodes, and for each experiment we varied the number of metrics emitted by the dummy applications.

The designed features were compared against Prometheus configured in two distinct tree-shaped setups: the first setup, which we named \textbf{centralized Prometheus}, corresponds to the most typical configuration of a Prometheus server, where a single node collects and aggregates the metrics correspondent to all the nodes in the system, collecting a global view of the system (materializing a single-level tree). The second experimental setup, named \textbf{Prometheus tree}, corresponds to a more sophisticated setup where instead of having a single aggregating node, a portion of nodes in the system aggregate the metric values (effectively splitting the load among the aggregator nodes), these aggregator nodes, similarly to deMMon, are set up in the shape of a tree, and make use of federation to scrape the partially aggregated value from other prometheus. The generation of these configurations is performed in an automated manner through scripts. In addition, for both of the centralized and tree configurations, we also test setup a variation where every node in the system is an aggregator node, which aggregates the metrics provided by their local dummy application, and only export the aggregated value. It is important to mention that only the first two setups (centralized and tree) are, to our knowledge, the most representative of common Prometheus configurations, however, we include them to study the impact on the network cost of performing in-transit aggregation by every node when compared to performing the aggregation of metrics corresponding to multiple nodes on a single node.

\subsection{Tree aggregation}

For the \textbf{tree aggregation} evaluation, we configured deMMon with a single tree aggregation function, which triggers the algorithm defined in section \ref{sec:mon_protocol} that, in sum, collects an aggregated value of the metrics of its descendants in the deMMon tree. This feature was designed for decentralized resource management applications that follow the deMMon hierarchical structure to perform decentralized resource management decisions. For example, a certain application that wishes to maintain a certain ratio of two service replicas (because one depends on the other), it can do so by having each node monitor its descendants and perform resource management actions (possibly coordinated with other nodes) to replenish or decommission a service replica to maintain the desired ratio.



\subsection{Global aggregation}